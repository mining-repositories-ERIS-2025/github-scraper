Categories:
  exlusions:
  - name: "race conditions"
    keywords:
    - name: "atomic"
      reason: "The keyword is either used for atomic operations as in all or nothin or "
      examples:
      - '{"repository": "https://github.com/django/django", "hashId": "ee20e2d0380e3f4f87c0ea386c7365056473d6ad", "msg": "Fixed typos in Atomic docstring.", "modified_file": {"added_lines": [[159, "    A stack of savepoint identifiers is maintained as an attribute of the"], [168, "    An atomic block can be tagged as durable. In this case, a RuntimeError is"], [169, "    raised if it"s nested within another atomic block. This guarantees"], [171, "    the block exits without error."]], "deleted_lines": [[159, "    A stack of savepoints identifiers is maintained as an attribute of the"], [168, "    An atomic block can be tagged as durable. In this case, raise a"], [169, "    RuntimeError if it"s nested within another atomic block. This guarantees"], [171, "    the block exists without error."]]}, "token_changes": {"added_tokens": {"block": 3, "of": 2, "is": 2, "as": 2, "the": 2, "atomic": 2, "A": 1, "stack": 1, "savepoint": 1, "identifiers": 1, "maintained": 1, "an": 1, "attribute": 1, "An": 1, "can": 1, "be": 1, "tagged": 1, "durable": 1, "In": 1, "this": 1, "case": 1, "a": 1, "RuntimeError": 1, "raised": 1, "if": 1, "it": 1, "s": 1, "nested": 1, "within": 1, "another": 1, "This": 1, "guarantees": 1, "exits": 1, "without": 1, "error": 1}, "deleted_tokens": {"block": 3, "of": 2, "as": 2, "the": 2, "atomic": 2, "A": 1, "stack": 1, "savepoints": 1, "identifiers": 1, "is": 1, "maintained": 1, "an": 1, "attribute": 1, "An": 1, "can": 1, "be": 1, "tagged": 1, "durable": 1, "In": 1, "this": 1, "case": 1, "raise": 1, "a": 1, "RuntimeError": 1, "if": 1, "it": 1, "s": 1, "nested": 1, "within": 1, "another": 1, "This": 1, "guarantees": 1, "exists": 1, "without": 1, "error": 1}}, "category": "race conditions", "keyword_used": " atomic "}'
      - '{"repository": "https://github.com/lllyasviel/stable-diffusion-webui-forge", "hashId": "bb7dd7b64668d4b645dba38a3bc52be452d14eb8", "msg": "use an atomic operation to replace the cache with the new version", "modified_file": {"added_lines": [[33, "            cache_filename_tmp = cache_filename + \"-\""], [34, "            with open(cache_filename_tmp, \"w\", encoding=\"utf8\") as file:"], [37, "            os.replace(cache_filename_tmp, cache_filename)"], [38, ""]], "deleted_lines": [[33, "            with open(cache_filename, \"w\", encoding=\"utf8\") as file:"]]}, "token_changes": {"added_tokens": {"cache_filename_tmp": 3, "cache_filename": 2, "with": 1, "open": 1, "encoding": 1, "as": 1, "file": 1, "os": 1, "replace": 1}, "deleted_tokens": {"with": 1, "open": 1, "cache_filename": 1, "encoding": 1, "as": 1, "file": 1}}, "category": "race conditions", "keyword_used": " atomic "}'
      - '{"repository": "https://github.com/numba/numba", "hashId": "a1dad66cfb2a6a534eca90e759546f257f134621", "msg": "Fix typo on atomic add declaration", "modified_file": {"added_lines": [[513, "        ("declare double @___numba_atomic_double_add(double*, double)","]], "deleted_lines": [[513, "        (declare doubleQ @___numba_atomic_double_add(double*, double),"]]}, "token_changes": {"added_tokens": {}, "deleted_tokens": {}}, "category": "race conditions", "keyword_used": " atomic "}'
    - 
  - name: " race" # replaced by  " race "
    reason: "seems like racey is being used for suspicion and not verified causes and used for removing defensive programming"
    examples:
    - '{"repository": "https://github.com/matrix-org/synapse", "hashId": "618d405a322590d022d839b6d72ba51e992a71c3", "msg": "Remove racey assertion in MultiWriterIDGenerator (#8530)\n\nWe asserted that the IDs returned by postgres sequence was greater than\r\nany we had seen, however this is technically racey as we may update the\r\ncurrent positions out of order.\r\n\r\nWe now assert that the sequences are correct on startup, so the\r\nassertion is no longer really required, so we remove them.", "modified_file": {"added_lines": [], "deleted_lines": [[621, "        # Assert the fetched ID is actually greater than any ID weve already"], [622, "seen. If not, then the sequence and table have got out of sync"], [623, "  somehow."], [625, "            assert max(self.id_gen._current_positions.values(), default=0) < min("], [626, "                self.stream_ids"], [627, "            )"], [628, ""]]}, "token_changes": {"added_tokens": {}, "deleted_tokens": {"self": 2, "assert": 1, "max": 1, "id_gen": 1, "_current_positions": 1, "values": 1, "default": 1, "min": 1, "stream_ids": 1}}, "category": "race conditions", "keyword_used": " race"}'
  - name: "null pointer"
    keywords:
    - name: "npe" # changed to " npe"
      reason: "npe is in lnpeer, which seems to be a popular library"
      examples:
      - '{"repository": "https://github.com/spesmilo/electrum", "hashId": "8c160e1b97231c638071d8e7c9280afcdf878efe", "msg": "lnpeer: maybe send update_fee right away after reestablish\n\nI just had a channel force-closed over a fee-estimate-disagreement :(\n\nScenario:\n1. started electrum, opened wallet\n2. waited around 10 seconds, opened the lightning channels overview, saw that channels are open/ready\n3. after around 10 more seconds, scanned bolt11 invoice and tried to pay\n4. channel got force-closed\n\nBefore this commit, we only call maybe_update_fee via lnwatcher callbacks.\nThese callbacks trigger on events such as \"adb_set_up_to_date\", \"blockchain_updated\", \"network_updated\", \"fee\".\nIn my case there was a race that all these events triggered *before* the channel got reestablished\n(in fact before the peer handshake finished). And also, by chance there were none of these events after\nthe reestablish but before I sent the HTLC.\nWhen I sent the HTLC, the channel counterparty (eclair) sent back an \"error\" msg that the feerates are\ntoo different, which led us to do a local-force-close.\n\nI have other channels in this wallet (with other peers), which reestablished faster and got lucky with\ntiming: the lnwatcher callbacks came just in time to trigger update_fee for them.\n\n```\n20241017T222847.598163Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | handshake done for 03ecef675be448b615e6176424070673ef8284e0fd19d8be062a6cb5b130a0a0d1@lightning.electrum.org:9740\n20241017T222847.602594Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Sending INIT\n20241017T222847.641383Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Received INIT\n20241017T222847.655041Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Sending CHANNEL_REESTABLISH\n20241017T222847.658355Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | channel_reestablish (<redacted_shortchanid>): sent channel_reestablish with (next_local_ctn=157, oldest_unrevoked_remote_ctn=156)\n20241017T222847.659524Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | reestablish_channel was called but channel <redacted_shortchanid> already in peer_state <PeerState.REESTABLISHING: 1>\n20241017T222847.660491Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | reestablish_channel was called but channel <redacted_shortchanid> already in peer_state <PeerState.REESTABLISHING: 1>\n20241017T222847.661442Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | reestablish_channel was called but channel <redacted_shortchanid> already in peer_state <PeerState.REESTABLISHING: 1>\n20241017T222847.662768Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | reestablish_channel was called but channel <redacted_shortchanid> already in peer_state <PeerState.REESTABLISHING: 1>\n20241017T222847.669875Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Received QUERY_CHANNEL_RANGE\n20241017T222847.690318Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Received GOSSIP_TIMESTAMP_FILTER\n20241017T222847.705782Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Received CHANNEL_REESTABLISH\n20241017T222847.707932Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | channel_reestablish (<redacted_shortchanid>): received channel_reestablish with (their_next_local_ctn=157, their_oldest_unrevoked_remote_ctn=156)\n20241017T222847.712504Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | channel_reestablish (<redacted_shortchanid>): replayed 0 unacked messages. []\n20241017T222847.716096Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Sending CHANNEL_READY\n20241017T222847.738709Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | saved remote channel_update gossip msg for chan <redacted_shortchanid>\n20241017T222907.627447Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | lnpeer.pay len(route)=1\n20241017T222907.628927Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] |   0: edge=<redacted_shortchanid> hop_data=<OnionHopsDataSingle. payload={<redacted>}. hmac=None>\n20241017T222907.629184Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | adding trampoline onion to final payload\n20241017T222907.629405Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | lnpeer.pay len(t_route)=2\n20241017T222907.629653Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] |   0: t_node=03ecef675be448b615e6176424070673ef8284e0fd19d8be062a6cb5b130a0a0d1 hop_data=<OnionHopsDataSingle. payload={<redacted>}. hmac=<redacted>>\n20241017T222907.629894Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] |   1: t_node=<redacted> hop_data=<OnionHopsDataSingle. payload={<redacted>}. hmac=b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00>\n20241017T222907.631495Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | starting payment. len(route)=1.\n20241017T222907.633075Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | starting payment. htlc: UpdateAddHtlc(amount_msat=<redacted>, payment_hash=<redacted>, cltv_abs=<redacted>, timestamp=1729204147, htlc_id=66)\n20241017T222907.633385Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Sending UPDATE_ADD_HTLC\n20241017T222907.635118Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | send_commitment. chan <redacted_shortchanid>. ctn: 157.\n20241017T222907.643229Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Sending COMMITMENT_SIGNED\n20241017T222907.721929Z |    DEBUG | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Received ERROR\n20241017T222907.722621Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | remote peer sent error [DO NOT TRUST THIS MESSAGE]: local/remote feerates are too different: remoteFeeratePerKw=<redacted_low_val> localFeeratePerKw=50125. chan_id=<redacted>. is_known_chan_id=True\n20241017T222907.734272Z |    DEBUG | lnchannel.Channel.[<redacted_shortchanid>] | Setting channel state: OPEN -> FORCE_CLOSING\n20241017T222907.825540Z |     INFO | lnpeer.Peer.[LNWallet, 03ecef675b-98960573] | Disconnecting: GracefulDisconnect()\n```", "modified_file": {"added_lines": [[1397, "        self.maybe_update_fee(chan)  # if needed, update fee ASAP, to avoid force-closures from this"], [2267, "        if chan.get_state() != ChannelState.OPEN:"], [2268, "            return"]], "deleted_lines": []}, "token_changes": {"added_tokens": {"chan": 2, "self": 1, "maybe_update_fee": 1, "if": 1, "get_state": 1, "ChannelState": 1, "OPEN": 1, "return": 1}, "deleted_tokens": {}}, "category": "null pointer exceptions", "keyword_used": "npe"}'
  - name: "memory leaks"
    keywords:
    - name: " memory "
      reason: "This is too broad and mostly used for optimization"
      examples:
      - '{"repository": "https://github.com/astropy/astropy", "hashId": "e207c8a22728c8dad7554a122e1f5f8f0fb6aa8a", "msg": "Change ostream from meaning "wb" to "wb+" to allow writing of dask arrays to memory map.", "modified_file": {"added_lines": [[44, "    "ostream": wb+"","]], "deleted_lines": [[44, "    "ostream": "wb","]]}, "token_changes": {"added_tokens": {}, "deleted_tokens": {}}, "category": "memory leaks", "keyword_used": " memory"}'
      - '{"repository": "https://github.com/allenai/OLMo", "hashId": "b3f85283f237be9b9f27339f4fa1671df00c1172", "msg": "Free some more memory sooner", "modified_file": {"added_lines": [[634, "                        del optim_state_dict_to_load"], [636, "                        torch.cuda.empty_cache()"]], "deleted_lines": []}, "token_changes": {"added_tokens": {"del": 1, "optim_state_dict_to_load": 1, "torch": 1, "cuda": 1, "empty_cache": 1}, "deleted_tokens": {}}, "category": "memory leaks", "keyword_used": " memory"}'
    - name: "garbage collection"
      reason: "mostly used for optimization"
      examples:
      - '{"repository": "https://github.com/saleor/saleor", "hashId": "c1ec45e339f47239637718caf1c69b5252ce0f4c", "msg": "Set the garbage collection baseline immediately after preloading the ASGI app\n\nThis forces a garbage collection run after the app is loaded and tells the garbage collector never to attempt to free the objects it could not reach. This should speed up all subsequent collection cycles.", "modified_file": {"added_lines": [[9, "import gc"], [28, "    gc.collect()"], [29, "    gc.freeze()  # mark anything that remains as uncollectable to speed up future collections"]], "deleted_lines": []}, "token_changes": {"added_tokens": {"gc": 3, "import": 1, "collect": 1, "freeze": 1}, "deleted_tokens": {}}, "category": "memory leaks", "keyword_used": " free "}'
    - name: "free"
      reason: "It has a few positive corrects but a plethora of false positives due to optimization and 'feel free' "
      examples:
        - '{"repository": "https://github.com/facebookresearch/fairseq", "hashId": "cd5775f30184baa414a354d9f06b747344a8ba74", "msg": "avoid freezing batches unnecessarily (#3610)\n\nSummary:\nIn EpochBatchIterator, first_batch() freezes batches in order to\ngenerate the dummy_batch. We then freeze batches again in the call\nto next_epoch_itr(). We can avoid the second freeze and reduce\ntime to first iteration by about 50% in cases where we have a\ncallable batch_sampler.\n\nBefore:\n\n![Screen Shot 2021-06-10 at 5 08 22 PM](https://user-images.githubusercontent.com/35972327/121613200-d2366600-ca10-11eb-9d1d-bafc2403766a.png)\n\nAfter:\n\n![Screen Shot 2021-06-10 at 5 07 54 PM](https://user-images.githubusercontent.com/35972327/121613224-dfebeb80-ca10-11eb-9d5a-07be9440db77.png)\n\n# Before submitting\n\n- [ ] Was this discussed/approved via a Github issue? (no need for typos, doc improvements)\n- [ ] Did you read the [contributor guideline](https://github.com/pytorch/fairseq/blob/master/CONTRIBUTING.md)?\n- [ ] Did you make sure to update the docs?\n- [ ] Did you write any new necessary tests?\n\n## What does this PR do?\nFixes # (issue).\n\n## PR review\nAnyone in the community is free to review the PR once the tests have passed.\nIf we didnt discuss your PR in Github issues theres a high chance it will not be merged.\n\n## Did you have fun?\nMake sure you had fun coding \ufffd\n\nPull Request resolved: https://github.com/pytorch/fairseq/pull/3610\n\nReviewed By: myleott\n\nDifferential Revision: D29105845\n\nPulled By: msbaines\n\nfbshipit-source-id: 9795d46d70a99ad1218ce225092cc22ee3192bbc", "modified_file": {"added_lines": [[359, "        prev_epoch = self.epoch"], [367, "            if callable(self.batch_sampler) and prev_epoch != self.epoch:"]], "deleted_lines": [[366, "            if callable(self.batch_sampler):"]]}, "token_changes": {"added_tokens": {"self": 3, "prev_epoch": 2, "epoch": 2, "if": 1, "callable": 1, "batch_sampler": 1, "and": 1}, "deleted_tokens": {"if": 1, "callable": 1, "self": 1, "batch_sampler": 1}}, "category": "memory leaks", "keyword_used": " free "}'
        - '{"repository": "https://github.com/h2oai/wave", "hashId": "89a80f397dc68ea2badd80eee261149e33f63281", "msg": "fix: Check H2O_WAVE_APP_ADDRESS env var before scanning free port (#937)\n\nCo-authored-by: Derrick Liu <derrick.liu@issgovernance.com>", "modified_file": {"added_lines": [[21, "from urllib.parse import urlparse"], [61, "    app_address = urlparse(os.environ.get(H2O_WAVE_APP_ADDRESS, fhttp://{_localhost}:{_scan_free_port()}))"], [62, "    host = app_address.hostname"], [63, "    port = app_address.port"], [64, ""], [65, "    addr = fhttp://{host}:{port}"]], "deleted_lines": [[60, "    port = _scan_free_port()"], [61, "    addr = fhttp://{_localhost}:{port}"]]}, "token_changes": {"added_tokens": {"app_address": 3, "urlparse": 2, "port": 2, "from": 1, "urllib": 1, "parse": 1, "import": 1, "os": 1, "environ": 1, "get": 1, "host": 1, "hostname": 1, "addr": 1}, "deleted_tokens": {"port": 1, "_scan_free_port": 1, "addr": 1}}, "category": "memory leaks", "keyword_used": " free "}'
  - aware_of:
    - name: "race conditions"
      keywords:
      - name: "semaphore"
        examples:
        - reason: "Only moved two lines up. Needs context"
          change: '{"repository": "https://github.com/shinnytech/tqsdk-python", "hashId": "08ca45d9553f42a4732b1f8cbf54338107c5a042", "msg": "test: semaphore \u5728\u7ebf\u7a0b\u542f\u52a8\u524d\u521d\u59cb\u5316", "modified_file": {"added_lines": [[20, "        self.semaphore = threading.Semaphore(value=0)"]], "deleted_lines": [[22, "        self.semaphore = threading.Semaphore(value=0)"]]}, "token_changes": {"added_tokens": {"self": 1, "semaphore": 1, "threading": 1, "Semaphore": 1, "value": 1}, "deleted_tokens": {"self": 1, "semaphore": 1, "threading": 1, "Semaphore": 1, "value": 1}}, "category": "race conditions", "keyword_used": " semaphore "}'
        - reason: "removed semaphore"
          change: '{"repository": "https://github.com/HKUDS/LightRAG", "hashId": "1192727be7cde4853e887b64cb24637736c27b33", "msg": "remove semaphore logic from EmbeddingFunc(cause num of instances is already control by limit_async_func_call)", "modified_file": {"added_lines": [[64, "        return await self.func(*args, **kwargs)"]], "deleted_lines": [[63, "    def __post_init__(self):"], [64, "        if self.concurrent_limit != 0:"], [65, "            self._semaphore = asyncio.Semaphore(self.concurrent_limit)"], [66, "        else:"], [67, "            self._semaphore = UnlimitedSemaphore()"], [68, ""], [70, "        async with self._semaphore:"], [71, "            return await self.func(*args, **kwargs)"]]}, "token_changes": {"added_tokens": {"return": 1, "await": 1, "self": 1, "func": 1, "args": 1, "kwargs": 1}, "deleted_tokens": {"self": 7, "_semaphore": 3, "concurrent_limit": 2, "def": 1, "__post_init__": 1, "if": 1, "asyncio": 1, "Semaphore": 1, "else": 1, "UnlimitedSemaphore": 1, "async": 1, "with": 1, "return": 1, "await": 1, "func": 1, "args": 1, "kwargs": 1}}, "category": "race conditions", "keyword_used": " semaphore "}'
  debateable:
    keywords:
    - name: "sempahore"
      reason: "Change semaphore and lock"
      examples: 
      - '{"repository": "https://github.com/ansible/ansible-lint", "hashId": "2639169c34e09281f264a8f387248d7f61ddafe2", "msg": "Avoid resource leak warning with multiprocessing Semaphore (#2365)", "modified_file": {"added_lines": [[143, "        # avoid resource leak warning, https://github.com/python/cpython/issues/90549"], [144, "        # pylint: disable=unused-variable"], [145, "        global_resource = multiprocessing.Semaphore()"], [146, ""]], "deleted_lines": []}, "token_changes": {"added_tokens": {"global_resource": 1, "multiprocessing": 1, "Semaphore": 1}, "deleted_tokens": {}}, "category": "race conditions", "keyword_used": " semaphore "}'
    - name: "semaphore"
      reason: "added to avoid performance (1: resource leak, 2. resource intensive process)"
      examples:
      - '{"repository": "https://github.com/ansible/ansible-lint", "hashId": "2639169c34e09281f264a8f387248d7f61ddafe2", "msg": "Avoid resource leak warning with multiprocessing Semaphore (#2365)", "modified_file": {"added_lines": [[143, "        # avoid resource leak warning, https://github.com/python/cpython/issues/90549"], [144, "        # pylint: disable=unused-variable"], [145, "        global_resource = multiprocessing.Semaphore()"], [146, ""]], "deleted_lines": []}, "token_changes": {"added_tokens": {"global_resource": 1, "multiprocessing": 1, "Semaphore": 1}, "deleted_tokens": {}}, "category": "race conditions", "keyword_used": " semaphore "}'
      - '{"repository": "https://github.com/lbryio/lbry-sdk", "hashId": "7ed5fe8f66a8cfe31eac63d87851c4fb2f772b89", "msg": "add semaphore on active estimation to avoid abuse", "modified_file": {"added_lines": [[32, "        self.active_estimation_semaphore = asyncio.Semaphore(1)"], [65, "        with self.active_estimation_semaphore:  # this is resource intensive, limit concurrency to 1"], [66, "            peers = await self.dht_node.peer_search(self.dht_node.protocol.node_id, count=amount, max_results=amount)"]], "deleted_lines": [[64, "        peers = await self.dht_node.peer_search(self.dht_node.protocol.node_id, count=amount, max_results=amount)"]]}, "token_changes": {"added_tokens": {"self": 4, "active_estimation_semaphore": 2, "dht_node": 2, "amount": 2, "asyncio": 1, "Semaphore": 1, "with": 1, "peers": 1, "await": 1, "peer_search": 1, "protocol": 1, "node_id": 1, "count": 1, "max_results": 1}, "deleted_tokens": {"self": 2, "dht_node": 2, "amount": 2, "peers": 1, "await": 1, "peer_search": 1, "protocol": 1, "node_id": 1, "count": 1, "max_results": 1}}, "category": "race conditions", "keyword_used": " semaphore "}'
    - name: " leak "
      reason: "Enables a flag that is able to compile to program with better debugging"
      examples:
      - '{"repository": "https://github.com/mesonbuild/meson", "hashId": "29c26d5b26397eaa3606d22d71309ecd1eb6b223", "msg": "compilers: Add support for stand-alone leak sanitizer\n\nLeak sanitizer can be enabled without the whole AddressSanitizer, this\ncan be done by passing -fsanitize=leak as documented at [1].\n\nMeson doesn"t support this, so add support for it.\n\n[1] https://clang.llvm.org/docs/LeakSanitizer.html", "modified_file": {"added_lines": [[281, "                                                      ["none", "address", "thread", "undefined", "memory", "leak", "address,undefined"],"]], "deleted_lines": [[281, "                                                      ["none", "address", "thread", "undefined", "memory", "address,undefined"],"]]}, "token_changes": {"added_tokens": {}, "deleted_tokens": {}}, "category": "memory leaks", "keyword_used": "leak "}'
  comments:
  - 'remember spaces so that words like "race" do not get matched with traceback'
